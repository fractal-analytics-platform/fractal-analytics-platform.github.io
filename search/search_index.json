{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Fractal","text":"<p>Fractal is a framework developed at the BioVisionCenter to process bioimaging data at scale in the OME-Zarr format and prepare the images for interactive visualization.</p> <p></p> <p>Fractal enables distributed workflows that convert TBs of image data into OME-Zarr files. Tasks are modular and can be provided by users to apply image processing and measurements. We provide a package of core processing tasks that include registration, segmentation and measurements. All tasks can be orchestrated by Fractal to run locally or on clusters to scale the image analysis. You can build &amp; control Fractal workflows via the web client or the Fractal command line client.</p> <p>The resulting pyramidal OME-Zarr files enable interactive visualization in different modern viewers like MoBIE and napari. </p>"},{"location":"#fractal-components","title":"Fractal components","text":"<p>Fractal is made of different components, including a server/client architecture, a web client and a set of core tasks for image processing.</p> Component GitHub Repository Documentation Package server fractal-server fractal-server docs fractal-server on PyPI client fractal-client fractal-client docs fractal-client on PyPI web client fractal-web fractal-web docs - core tasks fractal-tasks-core fractal-tasks-core docs fractal-tasks-core on PyPI"},{"location":"#status","title":"Status","text":"<p>Fractal is under active development. We have tasks in our core repository and in multiple other tasks repositories. Our core repository contains a converter for Yokogawa CV7000/CV8000 image data as well as different processing tasks for illumination correction, maximum intensity projection, cellpose segmentation. We're working with others to expand the number of compatible OME-Zarr converters (see e.g. fractal-faim-hcs, which uses the faim-hcs converters for the MD Image Xpress), additional image processing tasks (see e.g. APx Fractal Task Collection for tasks centered around 2D image analysis and drug profiling) and additional processing tasks (e.g. the scMultipleX package, which contains a Fractal task to make many scikit-image based measurements in 2D and 3D, as well as organoid registration for multiplexed images). Follow along on the github repositories above and feel free to open issues.</p>"},{"location":"#build-your-own-task","title":"Build your own task","text":"<p>You can easily add your own task to Fractal. Fractal can run Linux executables that follow its task API, as defined in the task building documentation. We primarily run Python-based tasks. You can find a full walk-through and templates in the Build Your Own Fractal Task page.</p>"},{"location":"#examples","title":"Examples","text":"<p>Example datasets and workflows are publicly available:</p> <ul> <li>Example output data from Fractal in the OME-Zarr format can be found here: Small dataset: 10.5281/zenodo.10257149, larger dataset: 10.5281/zenodo.10257532</li> <li>Example input datasets can be found here: Small Fractal dataset for automated testing &amp; task development, Larger example input data for Fractal.</li> <li>Additional example workflows can be found in the fractal-demos repository in the <code>examples</code> folder. </li> </ul>"},{"location":"#contributors-and-license","title":"Contributors and license","text":"<p>Unless otherwise stated in each individual module, all Fractal components are released according to a BSD 3-Clause License, and Copyright is with the BioVisionCenter at the University of Zurich.</p> <p>Fractal was conceived in the Liberali Lab at the Friedrich Miescher Institute for Biomedical Research and in the Pelkmans Lab at the University of Zurich by @jluethi and @gusqgm. The Fractal project is now developed at the BioVisionCenter at the University of Zurich and the project lead is with @jluethi. The core development is done under contract by eXact lab S.r.l..</p>"},{"location":"build_your_own_fractal_task/","title":"Build a Fractal task","text":"<p>Fractal tasks are the core processing units of to build your workflows. Each Fractal task loads the data from one (or many) OME-Zarr(s) and applies processing to them. Fractal tasks are Linux command line executables. For the purpose of this demo, we will look at the Python implementation. You can think of a Fractal task as a Python function that knows how to process an OME-Zarr image and save the results back into that OME-Zarr image. With a bit of syntax sugar, this becomes a Fractal task you can then run from the web interface. To understand the types of tasks, their API &amp; how they provide information to Fractal server, check out the V2 Tasks page. </p> <p>This page is all about building your own Fractal task. It comes down to 5 steps:  </p> <ol> <li> <p>Create a repository for your tasks using the fractal-tasks-template.  </p> </li> <li> <p>Develop your Python function to process an OME-Zarr as desired &amp; follow the Fractal API for task input &amp; function outputs.  </p> </li> <li> <p>Update the task-list to generate a Fractal manifest in your package.  </p> </li> <li> <p>Package your task (locally or via pypi).  </p> </li> <li> <p>Install your task on a given Fractal server.  </p> </li> </ol> <p>This video walks you through all those steps for how to implement a custom Fractal task that does image-labeling based on a user-defined threshold.</p> <p></p> <p>If you prefer to follow a written guide, follow the instructions in the README of fractal-tasks-template.</p>"},{"location":"run_fractal/","title":"Deploy Fractal Server &amp; Fractal Web","text":"<p>Fractal runs locally on a laptop (tested both Linux, macOS and Windows with subsystem Linux) or on a Linux server that submits jobs to a SLURM cluster. The <code>fractal-server</code> documentation describes the preconditions and the different configurations that can be changed.</p> <p>Fractal can be used via a command line client, as well as via a web client. To get started with Fractal, you can follow the setup in the fractal-demos repository.</p> <p>Here is a video walk-through for how to set up a local Fractal server:</p> <p></p> <p>Once you have a Fractal server running, you can also access it via Fractal web. To do so, set up a Fractal web server as shown here:</p> <p></p> <p>If you prefer to follow a written guide, follow the instructions in the server folder to set up Fractal server. Once you have successfully installed and started the Fractal server, you can install a fractal-client environment and interact with the Fractal server from there. To do so, follow the instructions for the 01_cardio_tiny_dataset example. This also includes a link to a tiny dataset and instructions on how to run a full Fractal workflow on this dataset (which should run in under a minute). To set up Fractal web, follow the instructions in the Fractal web README. </p>"},{"location":"version_2/","title":"Fractal V2","text":"<p>This section describes the main concepts introduced with the new Fractal version (version 2 of the <code>fractal-server</code> backend):</p> <ol> <li>The new dataset image list;</li> <li>The new definition of tasks.</li> </ol>"},{"location":"version_2/image_list/","title":"Image list","text":"<p>While applying a processing workflow to a given dataset, Fractal keeps a list of all the OME-Zarr images it is processing. In this page we describe the concepts of images and filters - see also the examples section.</p>"},{"location":"version_2/image_list/#images","title":"Images","text":"<p>Each entry in the image list is defined by a unique <code>zarr_url</code> property (the full path to the OME-Zarr image), and it may also include image types and image attributes.</p>"},{"location":"version_2/image_list/#image-types","title":"Image types","text":"<p>Image types are boolean properties that allow to split the image list into different sub-lists (e.g. the <code>is_3D</code> type for 3D/2D images, or the <code>illumination_corrected</code> type for raw/corrected images when illumination correction was not run in-place). Types can be set both by the task manifest (e.g. after an MIP task, the resulting images always have the type <code>is_3D</code> set to <code>False</code> - see task-manifest section) as well as from within an individual task (see task-API/output section).</p> <p>Note: whenever applying filters to the image list, the absence of a type corresponds to false by default.</p>"},{"location":"version_2/image_list/#image-attributes","title":"Image attributes","text":"<p>Image attributes are scalar properties (strings, integers, floats or booleans). They are always defined from within individual tasks, and never by the task manifest. They allow selecting subsets of your data (e.g. select a given well, a given plate or a given multiplexing acquisition).</p> <p>Fractal server uses the image list combined with filters (see below) to provide the right image URLs to tasks.</p>"},{"location":"version_2/image_list/#filters","title":"Filters","text":"<p>Before running a given task, Fractal prepares an appropriate image list by extracting the images that match with a given set of filters (that is, a set of specific values assigned to image types and/or image attributes). Filters can be defined for a dataset and/or for a workflow task. If a specific filter is set both for the dataset and for the workflow task, the workflow-task one takes priority.</p>"},{"location":"version_2/image_list/#dataset-filters","title":"Dataset filters","text":"<p>There are multiple ways a dataset may have a given filter set:</p> <ol> <li>I manually set it, by modifying the dataset <code>filters</code> property.</li> <li>While writing the Fractal manifest for a task package, I include the <code>output_types</code> attribute for a given task. These types are automatically included in the dataset filters after the task is run.  Examples:<ul> <li>An MIP task would have <code>output_types = {\"is_3D\": False}</code>: from this task onwards, the 2D images are processed (not the raw 3D images).</li> <li>An illumination-correction task would have <code>output_types = {\"illumination_corrected\": True}</code>: from this task onwards, the registered images are processed (not the raw images).</li> </ul> </li> <li>When writing the code for a specific task, the task output, I can include a <code>filters</code> property, for either image attributes and/or types - see the section on task outputs.</li> </ol> <p>Examples:</p> <ul> <li>My dataset currently has the type filter <code>{\"is_3D\": False}</code>, because I previously ran an MIP task. Subsequent tasks in the workflow will run on 2D images by default.</li> <li>My dataset currently has the attribute filter <code>{\"well\": \"B03\"}</code>, because I manually added it to the dataset (I just want to process a single well for the time being).</li> <li>My dataset currently has the attribute filter <code>{\"acquisition\": 1}</code>, because I manually added it to the dataset (I just want to process a single multiplexing acquisition).</li> </ul>"},{"location":"version_2/image_list/#workflow-task-filters","title":"Workflow-task filters","text":"<p>I can manually set an additional input filter by modifying the workflow-task <code>input_filters</code> property. </p> <p>Examples:</p> <ul> <li>I may need a workflow that includes the MIP task but then switches back to 3D images in a later task. I can achieve this by setting <code>input_filters = {\"is_3D\": True}</code> for the relevant task, so that from this task onwards the 3D images is processed (and not the 2D ones).</li> </ul>"},{"location":"version_2/image_list/#additional-validation","title":"Additional validation","text":"<p>Task manifest may also specify the <code>input_types</code> of a given task. These are not used for filtering the image list, but rather to validate that the filtered image list is valid. If some images of the filtered list do not comply with <code>input_types</code>, the Fractal runner raises an error.</p> <p>Examples:</p> <ul> <li>The illumination-correction task has <code>input_types={\"illumination_corrected\": False}</code>, which means it cannot run on images with type <code>illumination_correction=True</code>.</li> <li>The Apply Registration to Image task has <code>input_types={\"registered\": False}</code>, which means it cannot run on images with type <code>registered=True</code>.</li> </ul> <p>Note: as part of an upcoming <code>fractal-web</code> update, it may become possible to see/edit the current filters upon job submission.</p>"},{"location":"version_2/image_list/#examples","title":"Examples","text":"<p>After running a converter task, I may have an OME-Zarr HCS plate with 2 wells that contain one image each. In this case, the image list has 2 entries and each image has attributes for plate and well, as well as a true/fals <code>is_3D</code> type.</p> <p></p> <p>If I then run an illumination-correction task that does not overwrite its input images, the image list includes the two original images (without the <code>illumination_corrected</code> type) and two new ones (with <code>illumination_corrected</code> type set to true). Note that this task also sets the dataset type filters to <code>{\"illumination_correction\": True}</code>.</p> <p></p> <p>If I then run an MIP task, this will act on the two images with <code>illumination_corrected</code> set to true, due to the dataset filters. After the task has run, two new images are added to the list (with type <code>is_3D</code> set to false).</p> <p></p> <p>Another example is that if I have an OME-Zarr HCS plate with 3 wells and each well has 3 multiplexing acquisition, then the image list includes 9 OME-Zarr images (and those entries should have the acquisition attribute set).</p>"},{"location":"version_2/tasks/","title":"Tasks","text":"<p>Fractal v2 brings a large refactor to the task architecture to make tasks more flexible and allow for building more complex workflows, while also simplifying the task API. This page gives an overview over the different types of Fractal tasks, their input and output API and the elements that go into the Fractal task list.</p>"},{"location":"version_2/tasks/#task-types","title":"Task Types","text":"<p>There are three types of tasks in Fractal V2: parallel tasks, non-parallel tasks &amp; compound tasks.</p> <ol> <li>A parallel task is written to process a single OME-Zarr image and meant to be run in parallel across many OME-Zarr images. This is the typical scenario for compute tasks that don't need special input handling or subset parallelization</li> <li>A non-parallel task processes a list of images, and it only runs as a single job. It is useful to handle image-list updates and validation of Zarr collections (like Import OME-Zarr).</li> <li>A compound task consists of an initialization (non-parallel) task, that provides a custom parallelization list to a subsequent (parallel) compute task. An example are registration tasks that need to run across multiple Zarr images, but parallelize over wells of a multi-well plate. The init task is like a non-parallel task, but it provides the parallelization list as output. The compute task is like a parallel task, but it takes an extra <code>init_args</code> dictionary as input from the init task.</li> </ol>"},{"location":"version_2/tasks/#input-api","title":"Input API","text":""},{"location":"version_2/tasks/#parallel-tasks","title":"Parallel tasks","text":"<p>The input arguments of a Fractal parallel tasks must include a <code>zarr_url</code> string argument. The <code>zarr_url</code> contains the full path to the zarr file to be processed. Only filesystem paths are currently supported, not S3 urls. <code>zarr_url</code> is a reserved keyword argument: when running tasks through Fractal server, the server takes care to pass the correct <code>zarr_url</code> argument to the parallel task (based on filtering the image list). Tasks can also take an arbitrary list of additional arguments that are specific to the task function and that the user can set.</p>"},{"location":"version_2/tasks/#non-parallel-tasks","title":"Non-parallel tasks","text":"<p>The input arguments of a Fractal non-parallel task must include a <code>zarr_urls</code> arguments (a list of strings) and <code>zarr_dir</code> argument (a single string). <code>zarr_urls</code> contains the full paths to the OME-Zarr images to be processed. We currently just support paths on filesystems, not S3 urls. <code>zarr_dir</code> is typically the base directory into which OME-Zarr files will be written by tasks and it is mostly used by converters. Both <code>zarr_urls</code> and <code>zarr_dir</code> are reserved keyword arguments: when running tasks through Fractal server, the server takes care to pass the correct filtered list <code>zarr_urls</code> and the correct <code>zarr_dir</code> to the non-parallel task. Tasks can also take an arbitrary list of additional arguments that are specific to the task function and that the user can set.</p>"},{"location":"version_2/tasks/#compound-tasks","title":"Compound tasks","text":"<p>Compound tasks consist of an init part (similar to the non-parallel task) and a compute part (similar to the parallel task). The init part has the same Input API as the non-parallel task (<code>zarr_urls</code> and <code>zarr_dir</code>), but it provides the parallelization list for the compute part as an output. The compute part takes the <code>zarr_url</code> argument and an extra <code>init_args</code> dictionary argument (which is coming from the <code>parallelization_list</code> provided by the init task).</p>"},{"location":"version_2/tasks/#output-api","title":"Output API","text":"<p>Tasks can optionally return updates to the image list and/or new dataset filters (this is true for all tasks except the init phase of a compound tasks) or a parallelization list (just the init phase of a compound task). The output of a task is always a <code>task_output</code> dictionary. Note that this dictionary must be JSON-serializable, since it will be written to disk so that <code>fractal-server</code> can access it.</p> <p>For tasks that create new images or edit relevant image properties, <code>task_output</code> must include an <code>image_list_updates</code> property so the server can update its metadata about that image.</p> <p>NOTE: if both <code>image_list_updates</code> and <code>image_list_removals</code> are empty, in the task output, then <code>fractal-server</code> includes all the filtered image list in <code>image_list_updates</code>, so that they are updated with the appropriate <code>types</code> (see also the image-list page).</p> <p>Task outputs with image list updates are returned as a dictionary that contains the <code>image_list_updates</code> key and a list containing the updates to individual images. The updates need to be for unique <code>zarr_url</code>s and each update needs to contain the <code>zarr_url</code> of the image it\u2019s providing an update for. Additionally, they can provide an <code>origin</code> key, an <code>attributes</code> key and a <code>types</code> key. The <code>origin</code> key describes the <code>zarr_url</code> of another image already in the image list and will take the existing attributes and types from that image. Attributes and types can also be directly set by a task.</p> <p>Here's an example of <code>task_output</code>: <pre><code>{\n    \"image_list_updates\" = [\n        {\n            \"zarr_url\": \"/path/to/my_zarr.zarr/B/03/0_processed\",\n            \"origin\": \"/path/to/origin_zarr.zarr/B/03/0\",\n            \"attributes\": {\n                \"plate\": \"plate_name\",\n                \"well\": \"B03\"\n            },\n            \"types\": {\n                \"is_3D\": True\n            }\n        }\n    ]\n}\n</code></pre></p> <p>The init part of a compound task must produe a parallelization lists, with elements having the <code>zarr_url</code> property as well as additional arbitrary arguments as an <code>init_args</code> dictionary. Parallelization lists are provided in the following structure: <pre><code>{\n    \"parallelization_list\": [\n        {\n            \"zarr_url\": \"/path/to/my_zarr.zarr/B/03/0\",\n            \"init_args\": {\"some_arg\": \"some_value\"},\n        }\n    ]\n}\n</code></pre></p>"},{"location":"version_2/tasks/#task-list-and-manifest","title":"Task list and manifest","text":"<p>A package that provides Fractal tasks must contain a manifest (stored as a <code>__FRACTAL_MANIFEST__.json</code> file within the package), that describes the metadata of these tasks. <code>fractal-tasks-core</code> and <code>fractal-tasks-template</code> offer a simplified way to generate this manifest, based on a task list written in Python.</p> <p>For instance if the task package <code>my-pkg</code> was created based on the template, the task list is in <code>src/my-pkg/dev/task_list.py</code> and includes entries like <pre><code>TASK_LIST = [\n    NonParallelTask(\n        name=\"My non-parallel task\",\n        executable=\"my_non_parallel_task.py\",\n        meta={\"cpus_per_task\": 1, \"mem\": 4000},\n    ),\n    ParallelTask(\n        name=\"My parallel task\",\n        executable=\"my_parallel_task.py\",\n        meta={\"cpus_per_task\": 1, \"mem\": 4000},\n    ),\n    CompoundTask(\n        name=\"My compound task\",\n        executable_init=\"my_task_init.py\",\n        executable=\"my_actual_task.py\",\n        meta_init={\"cpus_per_task\": 1, \"mem\": 4000},\n        meta={\"cpus_per_task\": 2, \"mem\": 12000},\n    ),\n]\n</code></pre> where the different task models refer to the different task types. Given such task list, running the following command <pre><code>python src/my-pkg/dev/create_manifest.py\n</code></pre> generates a JSON file with the up-to-date manifest. Note that advanced usage may require minor customizations of the create-manifest script.</p>"}]}