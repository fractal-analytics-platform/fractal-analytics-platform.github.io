{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Fractal","text":"<p>Fractal is a framework developed at the BioVisionCenter to process bioimaging data at scale in the OME-Zarr format and prepare the images for interactive visualization.</p> <p></p> <p>Fractal enables distributed workflows that convert TBs of image data into OME-Zarr files. Tasks are modular and can be provided by users to apply image processing and measurements. We provide a package of core processing tasks that include registration, segmentation and measurements. All tasks can be orchestrated by Fractal to run locally or on clusters to scale the image analysis. You can build &amp; control Fractal workflows via the web client or the Fractal command line client.</p> <p>The resulting pyramidal OME-Zarr files enable interactive visualization in different modern viewers like MoBIE and napari. </p>"},{"location":"#fractal-components","title":"Fractal components","text":"<p>Fractal is made of different components, including a server/client architecture, a web client and a set of core tasks for image processing.</p> Component GitHub Repository Documentation Package server fractal-server fractal-server docs fractal-server on PyPI client fractal-client fractal-client docs fractal-client on PyPI web client fractal-web fractal-web docs - core tasks fractal-tasks-core fractal-tasks-core docs fractal-tasks-core on PyPI"},{"location":"#status","title":"Status","text":"<p>Fractal is under active development. We have tasks in our core repository and in multiple other tasks repositories. Our core repository contains a converter for Yokogawa CV7000/CV8000 image data as well as different processing tasks for illumination correction, maximum intensity projection, cellpose segmentation. We're working with others to expand the number of compatible OME-Zarr converters (see e.g. fractal-faim-hcs, which uses the faim-hcs converters for the MD Image Xpress), additional image processing tasks (see e.g. APx Fractal Task Collection for tasks centered around 2D image analysis and drug profiling) and additional processing tasks (e.g. the scMultipleX package, which contains a Fractal task to make many scikit-image based measurements in 2D and 3D, as well as organoid registration for multiplexed images). Follow along on the github repositories above and feel free to open issues.</p>"},{"location":"#build-your-own-task","title":"Build your own task","text":"<p>You can easily add your own task to Fractal. Fractal can run Linux executables that follow its task API, as defined in the task building documentation. We primarily run Python-based tasks. You can find a full walk-through and templates in the Build Your Own Fractal Task page.</p>"},{"location":"#examples","title":"Examples","text":"<p>Example datasets and workflows are publicly available:</p> <ul> <li>Example output data from Fractal in the OME-Zarr format can be found here: Small dataset: 10.5281/zenodo.10257149, larger dataset: 10.5281/zenodo.10257532</li> <li>Example input datasets can be found here: Small Fractal dataset for automated testing &amp; task development, Larger example input data for Fractal.</li> <li>Additional example workflows can be found in the fractal-demos repository in the <code>examples</code> folder. </li> </ul>"},{"location":"#contributors-and-license","title":"Contributors and license","text":"<p>Unless otherwise stated in each individual module, all Fractal components are released according to a BSD 3-Clause License, and Copyright is with the BioVisionCenter at the University of Zurich.</p> <p>Fractal was conceived in the Liberali Lab at the Friedrich Miescher Institute for Biomedical Research and in the Pelkmans Lab at the University of Zurich by @jluethi and @gusqgm. The Fractal project is now developed at the BioVisionCenter at the University of Zurich and the project lead is with @jluethi. The core development is done under contract by eXact lab S.r.l..</p>"},{"location":"build_your_own_fractal_task/","title":"Create a Fractal task","text":"<p>Fractal tasks are the core processing units of to build your workflows. Each Fractal task loads the data from one (or many) OME-Zarr(s) and applies processing to them. Fractal tasks are Linux command line executables. For the purpose of this demo, we will look at the Python implementation. You can think of a Fractal task as a Python function that knows how to process an OME-Zarr image and save the results back into that OME-Zarr image. With a bit of syntax sugar, this becomes a Fractal task you can then run from the web interface. To understand the types of tasks, their API &amp; how they provide information to Fractal server, check out the Fractal Tasks Spec page. </p> <p>This page is all about building your own Fractal task. It comes down to 5 steps:  </p> <ol> <li> <p>Create a repository for your tasks using the fractal-tasks-template.  </p> </li> <li> <p>Develop your Python function to process an OME-Zarr as desired &amp; follow the Fractal API for task input &amp; function outputs.  </p> </li> <li> <p>Update the task-list to generate a Fractal manifest in your package.  </p> </li> <li> <p>Package your task (locally or via pypi).  </p> </li> <li> <p>Install your task on a given Fractal server.  </p> </li> </ol> <p>This video walks you through all those steps for how to implement a custom Fractal task that does image-labeling based on a user-defined threshold.</p> <p></p> <p>If you prefer to follow a written guide, follow the instructions in the README of fractal-tasks-template.</p>"},{"location":"fractal_tasks/","title":"Fractal Tasks","text":"<p>Here is a list of task packages which can be used in Fractal. Note that not all existing packages are currently listed, see https://fractal-analytics-platform.github.io/fractal-tasks-core/all_tasks for a more complete list.</p> <p>(last updated: LASTUPDATEDPLACEHOLDER; <code>fractal-web</code> version: FRACTALWEBREFERENCEPLACEHOLDER)</p>"},{"location":"image_list/","title":"Fractal Image List","text":"<p>While applying a processing workflow to a given dataset, Fractal keeps a list of all the OME-Zarr images it is processing and their metadata. In this page we describe the concepts of images and filters - see also the examples section.</p>"},{"location":"image_list/#images","title":"Images","text":"<p>Each entry in the image list is defined by a unique <code>zarr_url</code> property (the full path to the OME-Zarr image), and it may also include image types and image attributes.</p>"},{"location":"image_list/#image-types","title":"Image types","text":"<p>Image types are boolean properties that allow to split the image list into different sub-lists (e.g. the <code>is_3D</code> type for 3D/2D images, or the <code>illumination_corrected</code> type for raw/corrected images when illumination correction was not run in-place). Types can be set both through the task manifest (e.g. after an MIP task, the resulting images always have the type <code>is_3D</code> set to <code>False</code>) as well as from within an individual task (see task-API/output section).</p> <p>Note: when applying filters to the image list, the absence of a type corresponds to false by default.</p>"},{"location":"image_list/#image-attributes","title":"Image attributes","text":"<p>Image attributes are scalar properties (strings, integers, floats or booleans). They are always defined from within individual tasks, and never by the task manifest. They allow selecting subsets of your data (e.g. select a given well, a given plate or a given multiplexing acquisition).</p> <p>Fractal server uses the image list combined with filters (see below) to provide the right image URLs to each task during execution.</p>"},{"location":"image_list/#filters","title":"Filters","text":"<p>Before running a given task, Fractal prepares an appropriate image list by extracting the images that match with a given set of filters. Filters can refer both to image types or image attributes and they may come from different sources.</p>"},{"location":"image_list/#type-filters","title":"Type filters","text":""},{"location":"image_list/#input-filters","title":"Input filters","text":"<p>The set of type filters to be applied before running a task is obtained by combining these sources:</p> <ol> <li>The dataset may have <code>type_filters</code> set - this is the source with lowest priority.<ul> <li>Example: A prior workflow ran and set output filters of <code>type_filters = {\"is_3D\": False}\"</code>. These output filters were added to the dataset when the prior workflow finished.</li> <li>Example: I manually set <code>type_filters = {\"illumination_corrected\": False}\"</code> through Fractal, by modifying the dataset, because I want to process raw images.</li> </ul> </li> <li>The manifest of a tasks package may specify that a task has some required <code>input_types</code>, which are used as filters.<ul> <li>Example: An \"Project Image (HCS Plate)\" task with <code>input_types={\"is_3D\": True}</code>, meaning that it cannot run on images with type <code>is_3D=False</code>.</li> <li>Example: An \"Illumination correction\" task with <code>input_types={\"illumination_corrected\": False}</code>, meaning that it cannot run on images with type <code>illumination_correction=True</code>.</li> <li>Example: An \"Apply Registration to Image\" task with <code>input_types={\"registered\": False}</code>, meaning that it cannot run on images with type <code>registered=True</code>.</li> </ul> </li> <li>For a task within a workflow, it is possible to specify some additional <code>type_filters</code>.<ul> <li>Example: I may need a workflow that includes a 3D-&gt;2D projection task but then switches back to 3D images in a later task. I can achieve this by setting <code>type_filters = {\"is_3D\": True}</code> for the relevant task, so that from this task onwards the 3D images are processed (and not the 2D ones).</li> </ul> </li> </ol>"},{"location":"image_list/#output-filters","title":"Output filters","text":"<p>The task manifest may include the <code>output_types</code> property for a specific task. If this is the case, then these types are both applied to all output images and they are included in the dataset <code>type_filters</code>.</p> <p>Examples:</p> <ul> <li>A 3D-&gt;2D projection task typically has <code>output_types = {\"is_3D\": False}</code>: from this task onwards, the 2D images are processed (not the raw 3D images). And the images generated by this task have their type set to <code>\"is_3D\": False</code>.</li> <li>An illumination-correction task would have <code>output_types = {\"illumination_corrected\": True}</code>: from this task onwards, the illumination corrected images are processed (not the raw images). And the images generated by this task have their type set to <code>\"illumination_corrected\": True</code>.</li> </ul>"},{"location":"image_list/#attribute-filters","title":"Attribute filters","text":"<p>The set of attribute filters to be applied before running a task is defined upon submission of a job, and they do not change during the job execution. These filters offer a way to process a subset of the whole dataset (e.g. only a few wells rather than the whole plate, or only a given multiplexing acquisition cycle). In Fractal web, the \"Continue Workflow\" dialogue is prepopulated with the attribute filters from the dataset (if any are set), but users are able to change the attribute filters to any setting they want.</p>"},{"location":"image_list/#examples","title":"Examples","text":"<p>After running a converter task, I may have an OME-Zarr HCS plate with 2 wells that contain one image each. In this case, the image list has 2 entries and each image has attributes for plate and well, as well as a true/false <code>is_3D</code> type.</p> <p></p> <p>If I then run an illumination-correction task that does not overwrite its input images, the image list includes the two original images (without the <code>illumination_corrected</code> type) and two new ones (with <code>illumination_corrected</code> type set to true). Note that this task also sets the dataset type filters to <code>{\"illumination_correction\": True}</code>.</p> <p></p> <p>If I then run an MIP task, this will act on the two images with <code>illumination_corrected</code> set to true, due to the dataset filters. After the task has run, two new images are added to the list (with type <code>is_3D</code> set to false).</p> <p></p> <p>Another example is that if I have an OME-Zarr HCS plate with 3 wells and each well has 3 multiplexing acquisition, then the image list includes 9 OME-Zarr images (and those entries should have the acquisition attribute set).</p>"},{"location":"run_fractal/","title":"Deploy Fractal","text":"<p>Fractal is meant to be deployed to manage workflows on large cluster and currently has support for different modes of running on slurm clusters. It is deployed on Linux servers and also runs on macOS or Windows (by using Windows Subsystem Linux). You can run a fully containerized local example that is useful for demos and testing purposes by following the instructions in the fractal containers repository or by following along this walkthrough:</p> <p></p> <p>More detailed documentation about the configuration of the different Fractal components can be found in the <code>fractal-server</code> documentation and the <code>fractal web</code> documentation.</p> <p>Fractal can also be deployed by manually setting up the server in a Python environment, configuring your own postgres database &amp; setting up Fractal web from source. You can find some helpful material for this in the  fractal-demos repository (especially the examples/server section). We also have older video walkthroughs on manual setups available for both the fractal-server as well as fractal-web.</p>"},{"location":"tasks_spec/","title":"Fractal Tasks Specification","text":"<p>Fractal tasks are modular and interoperable processing units that handle data in OME-Zarr containers. Each task is an executable that runs on a single OME-Zarr image or a collection of OME-Zarr images. In Fractal, we the OME-Zarrs to be processed by giving the tasks the zarr_urls(s), the paths to a given OME-Zarr image on disk or in the cloud. All tasks load data from an OME-Zarr on disk and store their processing results in an OME-Zarr (the same or a new one) on disk again. The parameters and metadata of tasks are described in a Fractal manifest in json form. This page contains an overview of the Fractal task specification, the types of Fractal tasks, the manifest that specifies task metadata as well as their input &amp; output API.</p> <p></p>"},{"location":"tasks_spec/#task-types","title":"Task Types","text":"<p>There are three types of tasks in Fractal V2: parallel tasks, non-parallel tasks &amp; compound tasks.</p> <ol> <li>A parallel task is written to process a single OME-Zarr image and meant to be run in parallel across many OME-Zarr images. <ul> <li>Parallel tasks are the typical scenario for compute tasks that don't need special input handling or subset parallelization. </li> <li>Parallel tasks can typically be run on any collection of OME-Zarrs.</li> </ul> </li> <li>A non-parallel task processes a list of images, and it only runs as a single job. <ul> <li>Non-parallel tasks are useful to aggregate information across many OME-Zarrs or to create image-list updates (see the Fractal image list).</li> <li>Non-parallel tasks can often be specific to given collection types like OME-Zarr HCS plates.</li> </ul> </li> <li>A compound task consists of an initialization (non-parallel) task and a (parallel) compute task.<ul> <li>The initialization task runs in the same way as a non-parallel task and generates a custom parallelization list of zarr_urls &amp; parameters to be used in the compute task.</li> <li>The compute tasks are run in parallel for each entry of the parallelization list and use the <code>init_args</code> dictionary as an extra input from the initialization task.</li> <li>Compound tasks can often be specific to given collection types like OME-Zarr HCS plates. A typical example are multiplexing-related tasks that use <code>acquisition</code> metadata on the well level to decide which pairs of images need to be processed.</li> </ul> </li> </ol>"},{"location":"tasks_spec/#task-list-and-manifest","title":"Task list and manifest","text":"<p>A package that provides Fractal tasks must contain a manifest (stored as a <code>__FRACTAL_MANIFEST__.json</code> file within the package), that describes the parameters, executables and metadata of the tasks. <code>fractal-tasks-core</code> and <code>fractal-tasks-template</code> offer a simplified way to generate this manifest, based on a task list written in Python. </p>"},{"location":"tasks_spec/#task-list","title":"Task list","text":"<p>If the task package <code>my-pkg</code> was created based on the template, the task list is in <code>src/my-pkg/dev/task_list.py</code> and includes entries like <pre><code>TASK_LIST = [\n    NonParallelTask(\n        name=\"My non-parallel task\",\n        executable=\"my_non_parallel_task.py\",\n        meta={\"cpus_per_task\": 1, \"mem\": 4000},\n        category=\"Conversion\",\n        docs_info=\"file:task_info/task_description.md\",\n        tags=[\"tag1\", \"Microscope name\"]\n    ),\n    ParallelTask(\n        name=\"My parallel task\",\n        executable=\"my_parallel_task.py\",\n        meta={\"cpus_per_task\": 1, \"mem\": 4000},\n        category=\"Segmentation\",\n    ),\n    CompoundTask(\n        name=\"My compound task\",\n        executable_init=\"my_task_init.py\",\n        executable=\"my_actual_task.py\",\n        meta_init={\"cpus_per_task\": 1, \"mem\": 4000},\n        meta={\"cpus_per_task\": 2, \"mem\": 12000},\n        category=\"Registration\",\n    ),\n]\n</code></pre> where the different task models refer to the different task types. Given such task list, running the following command <pre><code>python src/my-pkg/dev/create_manifest.py\n</code></pre> generates a JSON file with the up-to-date manifest. Note that advanced usage may require minor customizations of the create-manifest script.</p>"},{"location":"tasks_spec/#manifest-metadata","title":"Manifest metadata","text":"<p>The task manifest can contain additional metadata that makes it easier for people to browse tasks on the Fractal task page and the tasks available on a given server. The Fractal task template provides good defaults for how all this metadata can be set. This metadata is also used to make tasks searchable.</p>"},{"location":"tasks_spec/#docs-info","title":"Docs info","text":"<p>Tasks can provide a structured summary of their functionality. If the image list does not contain a docs_info property for a given task, the docstring of the task function is used. A developer can provide a more structured markdown file by specifying the relative path to the markdown file with the task description (for example: <code>file:task_info/task_description.md</code>). The convention for these task descriptions is to contain a section on the purpose of the task as well as its limitations in a bullet-point list.</p>"},{"location":"tasks_spec/#categories","title":"Categories","text":"<p>Tasks can belong to a single category, which allows users to filter for the kind of task they are looking for. The standard categories are: <code>Conversion</code>, <code>Image Processing</code>, <code>Segmentation</code>, <code>Registration</code>, <code>Measurement</code>.</p>"},{"location":"tasks_spec/#modalities","title":"Modalities","text":"<p>Tasks can have a single modality metadata. If a task works on all types of OME-Zarrs, no modality should be set. If a task is specifically designed to work on one modality (for example, a task that required OME-Zarr HCS plates), the modality should be specified. The standard modalities are: <code>HCS</code>, <code>lightsheet</code>, <code>EM</code>.</p>"},{"location":"tasks_spec/#tags","title":"Tags","text":"<p>Tasks can have arbitrary lists of string tags that describe their functionality. These are particularly helpful to increase the findability of a task using search.</p>"},{"location":"tasks_spec/#authors","title":"Authors","text":"<p>Task packages can specify an authors list. This metadata is configured in the create_manifest.py script for the whole task package.</p>"},{"location":"tasks_spec/#how-to-get-your-task-package-on-the-fractal-tasks-page","title":"How to get your task package on the Fractal tasks page","text":"<p>If you have a task package that you would like to see listed on the Fractal task page page, ping one of the Fractal maintainers about it or make a PR to have your task included in the list of task sources here. For a task package to be listable on the Fractal tasks page, the package needs to contain a Fractal manifest and be available either via PyPI or via a whl in Github releases. The Fractal task template provides examples for how to do both. Future work will add support for adding additional task configurations (likely a specification for how to provide packages that are installable via Pixi).</p>"},{"location":"tasks_spec/#input-api","title":"Input API","text":""},{"location":"tasks_spec/#parallel-tasks","title":"Parallel tasks","text":"<p>The input arguments of a Fractal parallel tasks must include a <code>zarr_url</code> string argument. The <code>zarr_url</code> contains the full path to the zarr file to be processed. Only filesystem paths are currently supported, not S3 urls. <code>zarr_url</code> is a reserved keyword argument: when running tasks through Fractal server, the server takes care to pass the correct <code>zarr_url</code> argument to the parallel task (based on filtering the image list). Tasks can also take an arbitrary list of additional arguments that are specific to the task function and that the user can set.</p>"},{"location":"tasks_spec/#non-parallel-tasks","title":"Non-parallel tasks","text":"<p>The input arguments of a Fractal non-parallel task must include a <code>zarr_urls</code> arguments (a list of strings) and <code>zarr_dir</code> argument (a single string). <code>zarr_urls</code> contains the full paths to the OME-Zarr images to be processed. We currently just support paths on filesystems, not S3 urls. <code>zarr_dir</code> is typically the base directory into which OME-Zarr files will be written by tasks and it is mostly used by converters. Both <code>zarr_urls</code> and <code>zarr_dir</code> are reserved keyword arguments: when running tasks through Fractal server, the server takes care to pass the correct filtered list <code>zarr_urls</code> and the correct <code>zarr_dir</code> to the non-parallel task. Tasks can also take an arbitrary list of additional arguments that are specific to the task function and that the user can set.</p>"},{"location":"tasks_spec/#compound-tasks","title":"Compound tasks","text":"<p>Compound tasks consist of an init part (similar to the non-parallel task) and a compute part (similar to the parallel task). The init part has the same Input API as the non-parallel task (<code>zarr_urls</code> and <code>zarr_dir</code>), but it provides the parallelization list for the compute part as an output. The compute part takes the <code>zarr_url</code> argument and an extra <code>init_args</code> dictionary argument (which is coming from the <code>parallelization_list</code> provided by the init task).</p>"},{"location":"tasks_spec/#output-api","title":"Output API","text":"<p>Tasks can optionally return updates to the image list (this is true for all tasks except the init phase of a compound tasks) or a parallelization list (just the init phase of a compound task). The output of a task is always a <code>task_output</code> dictionary. Note that this dictionary must be JSON-serializable, since it will be written to disk so that <code>fractal-server</code> can access it.</p> <p>For tasks that create new images or edit relevant image properties, <code>task_output</code> must include an <code>image_list_updates</code> property so the server can update its metadata about that image.</p> <p>NOTE: if both <code>image_list_updates</code> and <code>image_list_removals</code> are empty in the task output, then <code>fractal-server</code> includes all the filtered image list into <code>image_list_updates</code>, so that they are updated with the appropriate <code>types</code> (see also the image-list page).</p> <p>Task outputs with image list updates are returned as a dictionary that contains the <code>image_list_updates</code> key and a list containing the updates to individual images. The updates need to be for unique <code>zarr_url</code>s and each update needs to contain the <code>zarr_url</code> of the image it\u2019s providing an update for. Additionally, they can provide an <code>origin</code> key, an <code>attributes</code> key and a <code>types</code> key. The <code>origin</code> key describes the <code>zarr_url</code> of another image already in the image list and will take the existing attributes and types from that image. Attributes and types can also be directly set by a task.</p> <p>Here's an example of <code>task_output</code>: <pre><code>{\n    \"image_list_updates\" = [\n        {\n            \"zarr_url\": \"/path/to/my_zarr.zarr/B/03/0_processed\",\n            \"origin\": \"/path/to/origin_zarr.zarr/B/03/0\",\n            \"attributes\": {\n                \"plate\": \"plate_name\",\n                \"well\": \"B03\"\n            },\n            \"types\": {\n                \"is_3D\": True\n            }\n        }\n    ]\n}\n</code></pre></p> <p>The init part of a compound task must produe a parallelization lists, with elements having the <code>zarr_url</code> property as well as additional arbitrary arguments as an <code>init_args</code> dictionary. Parallelization lists are provided in the following structure: <pre><code>{\n    \"parallelization_list\": [\n        {\n            \"zarr_url\": \"/path/to/my_zarr.zarr/B/03/0\",\n            \"init_args\": {\"some_arg\": \"some_value\"},\n        }\n    ]\n}\n</code></pre></p>"}]}